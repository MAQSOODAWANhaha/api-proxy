//! # ç«¯åˆ°ç«¯APIæµ‹è¯•
//!
//! å¯åŠ¨çœŸå®æœåŠ¡ï¼Œé€šè¿‡HTTP APIè°ƒç”¨æµ‹è¯•å®Œæ•´çš„ä»£ç†åŠŸèƒ½ï¼š
//! 1. èº«ä»½éªŒè¯
//! 2. é€Ÿç‡é™åˆ¶  
//! 3. è½¬å‘ç­–ç•¥

use std::time::Duration;
use tokio::time::sleep;
use serde_json::{json, Value};
use reqwest::{Client, StatusCode};
use tokio::net::TcpListener;
use axum::{
    response::Json,
    routing::{get, post},
    Router, extract::Json as ExtractJson,
};
use chrono::Utc;

/// é»˜è®¤APIå¯†é’¥ï¼ˆæ¥è‡ªmigrationçš„é»˜è®¤adminæ•°æ®ï¼‰
const ADMIN_OPENAI_API_KEY: &str = "demo-admin-openai-key-123456789";
const ADMIN_GEMINI_API_KEY: &str = "demo-admin-gemini-key-123456789";
const ADMIN_CLAUDE_API_KEY: &str = "demo-admin-claude-key-123456789";
const INVALID_API_KEY: &str = "invalid-key-should-fail";

/// ç«¯åˆ°ç«¯APIæµ‹è¯•å¥—ä»¶
pub struct E2EApiTest {
    /// ä»£ç†æœåŠ¡å™¨ç«¯å£
    pub proxy_port: u16,
    /// Mockä¸Šæ¸¸æœåŠ¡å™¨ç«¯å£
    pub mock_upstream_port: u16,
    /// HTTPå®¢æˆ·ç«¯
    pub client: Client,
}

impl E2EApiTest {
    /// åˆ›å»ºæ–°çš„ç«¯åˆ°ç«¯æµ‹è¯•ç¯å¢ƒ
    pub async fn new() -> Result<Self, Box<dyn std::error::Error>> {
        println!("ğŸš€ åˆå§‹åŒ–ç«¯åˆ°ç«¯APIæµ‹è¯•ç¯å¢ƒ");
        
        // 1. æ‰¾å¯ç”¨ç«¯å£
        let proxy_port = find_available_port().await?;
        let mock_upstream_port = find_available_port().await?;
        
        println!("   ä»£ç†ç«¯å£: {}", proxy_port);
        println!("   Mockä¸Šæ¸¸ç«¯å£: {}", mock_upstream_port);
        
        // 2. å¯åŠ¨Mockä¸Šæ¸¸æœåŠ¡å™¨
        Self::start_mock_upstream_server(mock_upstream_port).await?;
        
        // 3. TODO: å¯åŠ¨çœŸå®ä»£ç†æœåŠ¡å™¨
        // Self::start_real_proxy_server(proxy_port).await?;
        
        // 4. ç­‰å¾…æœåŠ¡å™¨å¯åŠ¨
        sleep(Duration::from_secs(3)).await;
        
        Ok(Self {
            proxy_port,
            mock_upstream_port,
            client: Client::new(),
        })
    }
    
    /// å¯åŠ¨Mockä¸Šæ¸¸æœåŠ¡å™¨ï¼ˆæ¨¡æ‹ŸOpenAIã€Geminiã€Claude APIï¼‰
    async fn start_mock_upstream_server(port: u16) -> Result<(), Box<dyn std::error::Error>> {
        println!("ğŸ­ å¯åŠ¨Mockä¸Šæ¸¸æœåŠ¡å™¨ (ç«¯å£: {})", port);
        
        let app = Router::new()
            // OpenAI API endpoints
            .route("/v1/chat/completions", post(mock_openai_chat))
            .route("/v1/models", get(mock_openai_models))
            
            // Gemini API endpoints
            .route("/v1beta/models/gemini-pro:generateContent", post(mock_gemini_chat))
            .route("/v1beta/models", get(mock_gemini_models))
            
            // Claude API endpoints (use different path to avoid conflict)
            .route("/v1/messages", post(mock_claude_chat))
            .route("/v1/claude/models", get(mock_claude_models))
            
            // Health check
            .route("/health", get(mock_health));
        
        let listener = TcpListener::bind(format!("127.0.0.1:{}", port)).await?;
        
        tokio::spawn(async move {
            if let Err(e) = axum::serve(listener, app).await {
                eprintln!("MockæœåŠ¡å™¨é”™è¯¯: {}", e);
            }
        });
        
        Ok(())
    }
    
    /// æµ‹è¯•OpenAIæ­£å¸¸èŠå¤©è¯·æ±‚
    pub async fn test_openai_chat(&self) -> Result<(), Box<dyn std::error::Error>> {
        println!("ğŸ’¬ æµ‹è¯•OpenAIèŠå¤©è¯·æ±‚");
        
        let request_body = json!({
            "model": "gpt-3.5-turbo",
            "messages": [
                {
                    "role": "user",
                    "content": "Hello, test OpenAI API"
                }
            ],
            "max_tokens": 100,
            "temperature": 0.7
        });
        
        let response = self.client
            .post(&format!("http://127.0.0.1:{}/v1/chat/completions", self.proxy_port))
            .header("Authorization", format!("Bearer {}", ADMIN_OPENAI_API_KEY))
            .header("Content-Type", "application/json")
            .json(&request_body)
            .send()
            .await?;
        
        println!("   çŠ¶æ€ç : {}", response.status());
        
        if response.status() == StatusCode::OK {
            let response_body: Value = response.json().await?;
            println!("   âœ… OpenAIèŠå¤©è¯·æ±‚æˆåŠŸ");
            println!("   å“åº”: {}", serde_json::to_string_pretty(&response_body)?);
        } else {
            let error_text = response.text().await?;
            println!("   âŒ OpenAIèŠå¤©è¯·æ±‚å¤±è´¥: {}", error_text);
            return Err(format!("OpenAIèŠå¤©è¯·æ±‚å¤±è´¥: {}", error_text).into());
        }
        
        Ok(())
    }
    
    /// æµ‹è¯•Geminiæ­£å¸¸èŠå¤©è¯·æ±‚
    pub async fn test_gemini_chat(&self) -> Result<(), Box<dyn std::error::Error>> {
        println!("ğŸ”® æµ‹è¯•GeminièŠå¤©è¯·æ±‚");
        
        let request_body = json!({
            "contents": [{
                "parts": [{
                    "text": "Hello, test Gemini API"
                }]
            }]
        });
        
        let response = self.client
            .post(&format!("http://127.0.0.1:{}/v1beta/models/gemini-pro:generateContent", self.proxy_port))
            .header("Authorization", format!("Bearer {}", ADMIN_GEMINI_API_KEY))
            .header("Content-Type", "application/json")
            .json(&request_body)
            .send()
            .await?;
        
        println!("   çŠ¶æ€ç : {}", response.status());
        
        if response.status() == StatusCode::OK {
            let response_body: Value = response.json().await?;
            println!("   âœ… GeminièŠå¤©è¯·æ±‚æˆåŠŸ");
            println!("   å“åº”: {}", serde_json::to_string_pretty(&response_body)?);
        } else {
            let error_text = response.text().await?;
            println!("   âŒ GeminièŠå¤©è¯·æ±‚å¤±è´¥: {}", error_text);
            return Err(format!("GeminièŠå¤©è¯·æ±‚å¤±è´¥: {}", error_text).into());
        }
        
        Ok(())
    }
    
    /// æµ‹è¯•Claudeæ­£å¸¸èŠå¤©è¯·æ±‚
    pub async fn test_claude_chat(&self) -> Result<(), Box<dyn std::error::Error>> {
        println!("ğŸ¤– æµ‹è¯•ClaudeèŠå¤©è¯·æ±‚");
        
        let request_body = json!({
            "model": "claude-3-sonnet",
            "max_tokens": 100,
            "messages": [
                {
                    "role": "user",
                    "content": "Hello, test Claude API"
                }
            ]
        });
        
        let response = self.client
            .post(&format!("http://127.0.0.1:{}/v1/messages", self.proxy_port))
            .header("Authorization", format!("Bearer {}", ADMIN_CLAUDE_API_KEY))
            .header("Content-Type", "application/json")
            .header("anthropic-version", "2023-06-01")
            .json(&request_body)
            .send()
            .await?;
        
        println!("   çŠ¶æ€ç : {}", response.status());
        
        if response.status() == StatusCode::OK {
            let response_body: Value = response.json().await?;
            println!("   âœ… ClaudeèŠå¤©è¯·æ±‚æˆåŠŸ");
            println!("   å“åº”: {}", serde_json::to_string_pretty(&response_body)?);
        } else {
            let error_text = response.text().await?;
            println!("   âŒ ClaudeèŠå¤©è¯·æ±‚å¤±è´¥: {}", error_text);
            return Err(format!("ClaudeèŠå¤©è¯·æ±‚å¤±è´¥: {}", error_text).into());
        }
        
        Ok(())
    }
    
    /// æµ‹è¯•æ— æ•ˆAPIå¯†é’¥è®¤è¯
    pub async fn test_invalid_auth(&self) -> Result<(), Box<dyn std::error::Error>> {
        println!("ğŸ” æµ‹è¯•æ— æ•ˆAPIå¯†é’¥è®¤è¯");
        
        let request_body = json!({
            "model": "gpt-3.5-turbo",
            "messages": [{"role": "user", "content": "test"}]
        });
        
        let response = self.client
            .post(&format!("http://127.0.0.1:{}/v1/chat/completions", self.proxy_port))
            .header("Authorization", format!("Bearer {}", INVALID_API_KEY))
            .header("Content-Type", "application/json")
            .json(&request_body)
            .send()
            .await?;
        
        println!("   çŠ¶æ€ç : {}", response.status());
        
        if response.status() == StatusCode::UNAUTHORIZED {
            println!("   âœ… æ— æ•ˆAPIå¯†é’¥æ­£ç¡®æ‹’ç» (401)");
        } else {
            let error_text = response.text().await?;
            println!("   âŒ æ— æ•ˆAPIå¯†é’¥åº”è¯¥è¿”å›401ï¼Œå®é™…: {}", error_text);
            return Err("æ— æ•ˆAPIå¯†é’¥æµ‹è¯•å¤±è´¥".into());
        }
        
        Ok(())
    }
    
    /// æµ‹è¯•é€Ÿç‡é™åˆ¶
    pub async fn test_rate_limiting(&self) -> Result<(), Box<dyn std::error::Error>> {
        println!("â±ï¸  æµ‹è¯•é€Ÿç‡é™åˆ¶ï¼ˆç›®å‰å…ˆè·³è¿‡ï¼Œéœ€è¦çœŸå®æœåŠ¡å™¨ï¼‰");
        
        // TODO: å®ç°é€Ÿç‡é™åˆ¶æµ‹è¯•
        // éœ€è¦çœŸå®çš„ä»£ç†æœåŠ¡å™¨è¿è¡Œæ‰èƒ½æµ‹è¯•
        
        Ok(())
    }
    
    /// è¿è¡Œæ‰€æœ‰ç«¯åˆ°ç«¯æµ‹è¯•
    pub async fn run_all_tests(&self) -> Result<(), Box<dyn std::error::Error>> {
        println!("ğŸš€ å¼€å§‹ç«¯åˆ°ç«¯APIæµ‹è¯•");
        println!("==========================================");
        
        // å…ˆæµ‹è¯•MockæœåŠ¡å™¨æ˜¯å¦æ­£å¸¸
        sleep(Duration::from_secs(1)).await;
        
        // TODO: ç­‰çœŸå®ä»£ç†æœåŠ¡å™¨å¯åŠ¨åå†å¯ç”¨è¿™äº›æµ‹è¯•
        // self.test_openai_chat().await?;
        // println!();
        // 
        // self.test_gemini_chat().await?;
        // println!();
        // 
        // self.test_claude_chat().await?;
        // println!();
        // 
        // self.test_invalid_auth().await?;
        // println!();
        // 
        // self.test_rate_limiting().await?;
        // println!();
        
        println!("==========================================");
        println!("ğŸ‰ ç«¯åˆ°ç«¯APIæµ‹è¯•æ¡†æ¶å·²å‡†å¤‡å°±ç»ªï¼");
        println!("âœ¨ é»˜è®¤ç®¡ç†å‘˜è®¤è¯ä¿¡æ¯ï¼š");
        println!("   - OpenAI API Key: {}", ADMIN_OPENAI_API_KEY);
        println!("   - Gemini API Key: {}", ADMIN_GEMINI_API_KEY);
        println!("   - Claude API Key: {}", ADMIN_CLAUDE_API_KEY);
        println!("   - ç®¡ç†å‘˜ç”¨æˆ·å: admin");
        println!("   - ç®¡ç†å‘˜å¯†ç : admin123");
        
        Ok(())
    }
}

/// Mock OpenAIèŠå¤©æ¥å£
async fn mock_openai_chat(ExtractJson(payload): ExtractJson<Value>) -> Json<Value> {
    println!("ğŸ”— Mock OpenAI Chatè¢«è°ƒç”¨");
    
    let response = json!({
        "id": "chatcmpl-test-openai-12345",
        "object": "chat.completion",
        "created": Utc::now().timestamp(),
        "model": payload.get("model").unwrap_or(&json!("gpt-3.5-turbo")),
        "choices": [{
            "index": 0,
            "message": {
                "role": "assistant",
                "content": "è¿™æ˜¯æ¥è‡ªMock OpenAIæœåŠ¡å™¨çš„æµ‹è¯•å“åº”ã€‚"
            },
            "finish_reason": "stop"
        }],
        "usage": {
            "prompt_tokens": 10,
            "completion_tokens": 15,
            "total_tokens": 25
        }
    });
    
    Json(response)
}

/// Mock OpenAIæ¨¡å‹åˆ—è¡¨æ¥å£
async fn mock_openai_models() -> Json<Value> {
    Json(json!({
        "object": "list",
        "data": [
            {
                "id": "gpt-3.5-turbo",
                "object": "model",
                "created": Utc::now().timestamp(),
                "owned_by": "openai"
            }
        ]
    }))
}

/// Mock GeminièŠå¤©æ¥å£
async fn mock_gemini_chat(ExtractJson(_payload): ExtractJson<Value>) -> Json<Value> {
    println!("ğŸ”— Mock Gemini Chatè¢«è°ƒç”¨");
    
    let response = json!({
        "candidates": [{
            "content": {
                "parts": [{
                    "text": "è¿™æ˜¯æ¥è‡ªMock GeminiæœåŠ¡å™¨çš„æµ‹è¯•å“åº”ã€‚"
                }],
                "role": "model"
            },
            "finishReason": "STOP"
        }],
        "usageMetadata": {
            "promptTokenCount": 8,
            "candidatesTokenCount": 12,
            "totalTokenCount": 20
        }
    });
    
    Json(response)
}

/// Mock Geminiæ¨¡å‹åˆ—è¡¨æ¥å£
async fn mock_gemini_models() -> Json<Value> {
    Json(json!({
        "models": [
            {
                "name": "models/gemini-pro",
                "displayName": "Gemini Pro",
                "description": "The best model for scaling across a wide range of tasks"
            }
        ]
    }))
}

/// Mock ClaudeèŠå¤©æ¥å£
async fn mock_claude_chat(ExtractJson(payload): ExtractJson<Value>) -> Json<Value> {
    println!("ğŸ”— Mock Claude Chatè¢«è°ƒç”¨");
    
    let response = json!({
        "id": "msg-test-claude-12345",
        "type": "message",
        "role": "assistant",
        "content": [{
            "type": "text",
            "text": "è¿™æ˜¯æ¥è‡ªMock ClaudeæœåŠ¡å™¨çš„æµ‹è¯•å“åº”ã€‚"
        }],
        "model": payload.get("model").unwrap_or(&json!("claude-3-sonnet")),
        "stop_reason": "end_turn",
        "usage": {
            "input_tokens": 10,
            "output_tokens": 12
        }
    });
    
    Json(response)
}

/// Mock Claudeæ¨¡å‹åˆ—è¡¨æ¥å£
async fn mock_claude_models() -> Json<Value> {
    Json(json!({
        "data": [
            {
                "id": "claude-3-sonnet",
                "type": "model",
                "display_name": "Claude 3 Sonnet"
            }
        ]
    }))
}

/// Mockå¥åº·æ£€æŸ¥æ¥å£
async fn mock_health() -> Json<Value> {
    Json(json!({
        "status": "ok",
        "timestamp": Utc::now().timestamp()
    }))
}

/// æŸ¥æ‰¾å¯ç”¨ç«¯å£
async fn find_available_port() -> Result<u16, Box<dyn std::error::Error>> {
    let listener = TcpListener::bind("127.0.0.1:0").await?;
    let port = listener.local_addr()?.port();
    drop(listener);
    Ok(port)
}

#[cfg(test)]
mod tests {
    use super::*;

    #[tokio::test]
    async fn test_e2e_api_framework() {
        println!("ğŸ”§ æµ‹è¯•ç«¯åˆ°ç«¯APIæ¡†æ¶");
        
        let test_env = E2EApiTest::new().await
            .expect("åˆ›å»ºæµ‹è¯•ç¯å¢ƒå¤±è´¥");
        
        test_env.run_all_tests().await
            .expect("ç«¯åˆ°ç«¯APIæµ‹è¯•å¤±è´¥");
        
        println!("âœ… ç«¯åˆ°ç«¯APIæµ‹è¯•æ¡†æ¶éªŒè¯å®Œæˆ");
    }
}