//! # ç³»ç»Ÿé›†æˆæµ‹è¯•
//!
//! å…¨é¢æµ‹è¯•æ•´ä¸ªä»£ç†ç³»ç»Ÿçš„é›†æˆåŠŸèƒ½

use api_proxy::testing::{
    fixtures::{UserFixture, ProviderTypeFixture, UserProviderKeyFixture, TestConfig},
    helpers::{init_test_env, create_test_db, TestTransaction, PerformanceTest, MockPingoraSession, EnvTestHelper},
    mocks::{MockOpenAiProvider, MockAiProvider, MockTime, MockHttpServer}
};
use serde_json::json;

#[tokio::test]
async fn test_complete_testing_framework() {
    init_test_env();
    
    // 1. æµ‹è¯•æ•°æ®åº“å’Œäº‹åŠ¡
    let tx = TestTransaction::new().await.unwrap();
    
    // 2. æµ‹è¯•ç”¨æˆ· fixture
    let user_fixture = UserFixture::new()
        .username("test_integration_user")
        .email("integration@test.com")
        .admin();
    
    let user_id = tx.insert_test_user(user_fixture).await.unwrap();
    assert!(user_id > 0);
    
    // 3. æµ‹è¯•æä¾›å•†ç±»å‹ fixture - ä½¿ç”¨å”¯ä¸€åç§°é¿å…å†²çª
    let mut provider_fixture = ProviderTypeFixture::openai();
    provider_fixture.name = sea_orm::Set("test_openai_provider".to_string());
    let provider_id = tx.insert_provider_type(provider_fixture).await.unwrap();
    assert!(provider_id > 0);
    
    // 4. æµ‹è¯•ç”¨æˆ·æä¾›å•†å¯†é’¥ fixture
    let key_fixture = UserProviderKeyFixture::new()
        .user_id(user_id)
        .provider_type_id(provider_id)
        .name("Integration Test Key")
        .api_key("sk-integration-test-key")
        .weight(50);
    
    let key_model = key_fixture.to_active_model();
    assert_eq!(key_model.user_id.as_ref(), &user_id);
    assert_eq!(key_model.provider_type_id.as_ref(), &provider_id);
    assert_eq!(key_model.name.as_ref(), "Integration Test Key");
    
    // 5. æµ‹è¯•é…ç½®
    let config = TestConfig::app_config();
    assert_eq!(config.server.host, "127.0.0.1");
    assert_eq!(config.database.url, ":memory:");
    assert_eq!(config.redis.database, 15);
    
    // 6. æµ‹è¯• Mock AI æä¾›å•†
    let mock_provider = MockOpenAiProvider::new()
        .with_failure();
    
    let request = api_proxy::testing::mocks::ChatCompletionRequest {
        model: "gpt-3.5-turbo".to_string(),
        messages: vec![],
        temperature: Some(0.7),
        max_tokens: Some(100),
    };
    
    let result = mock_provider.chat_completion(request).await;
    assert!(result.is_err());
    
    // 7. æµ‹è¯•æ€§èƒ½æµ‹é‡
    let (result, duration) = PerformanceTest::measure(|| {
        std::thread::sleep(std::time::Duration::from_millis(1));
        42
    });
    assert_eq!(result, 42);
    assert!(duration >= std::time::Duration::from_millis(1));
    
    // 8. æµ‹è¯• Mock Time
    let mock_time = MockTime::new(chrono::Utc::now());
    let initial_time = mock_time.now();
    
    mock_time.advance(chrono::Duration::hours(1));
    let advanced_time = mock_time.now();
    
    assert!(advanced_time > initial_time);
    assert_eq!(
        advanced_time - initial_time,
        chrono::Duration::hours(1)
    );
}

#[tokio::test]
async fn test_database_operations() {
    init_test_env();
    
    let db = create_test_db().await.unwrap();
    
    // éªŒè¯å¯ä»¥è¿æ¥æ•°æ®åº“
    use sea_orm::ConnectionTrait;
    let backend = db.get_database_backend();
    assert!(!format!("{:?}", backend).is_empty());
}

#[test]
fn test_all_fixtures() {
    // æµ‹è¯•æ‰€æœ‰ fixture çš„åŸºæœ¬åŠŸèƒ½
    let user = UserFixture::new().admin().to_model_with_id(1);
    assert!(user.is_admin);
    
    let openai = ProviderTypeFixture::openai();
    assert_eq!(openai.name.as_ref(), "openai");
    
    let gemini = ProviderTypeFixture::gemini();
    assert_eq!(gemini.name.as_ref(), "gemini");
    
    let claude = ProviderTypeFixture::claude();
    assert_eq!(claude.name.as_ref(), "claude");
    
    let key = UserProviderKeyFixture::new()
        .weight(75)
        .api_key("sk-custom-key")
        .to_active_model();
    
    assert_eq!(key.weight.as_ref(), &Some(75));
    assert_eq!(key.api_key.as_ref(), "sk-custom-key");
}

#[tokio::test]
async fn test_mock_ai_provider_success() {
    let mock_provider = MockOpenAiProvider::new();
    
    let request = api_proxy::testing::mocks::ChatCompletionRequest {
        model: "gpt-4".to_string(),
        messages: vec![],
        temperature: Some(0.5),
        max_tokens: Some(150),
    };
    
    let response = mock_provider.chat_completion(request).await.unwrap();
    assert_eq!(response.model, "gpt-4");
    assert!(!response.choices.is_empty());
    assert!(response.usage.is_some());
    
    let health = mock_provider.health_check().await.unwrap();
    assert_eq!(health.status, "healthy");
}

#[tokio::test]
async fn test_performance_benchmarking() {
    let start = std::time::Instant::now();
    
    PerformanceTest::benchmark_async(
        "ç®€å•å¼‚æ­¥æ“ä½œ", 
        5, 
        || async {
            tokio::time::sleep(std::time::Duration::from_millis(1)).await;
        }
    ).await;
    
    let duration = start.elapsed();
    // åŸºå‡†æµ‹è¯•åº”è¯¥åœ¨åˆç†æ—¶é—´å†…å®Œæˆ
    assert!(duration < std::time::Duration::from_secs(1));
}

#[tokio::test] 
async fn test_session_mock_integration() {
    init_test_env();
    
    println!("ğŸ­ æµ‹è¯•ä¼šè¯æ¨¡æ‹Ÿå™¨é›†æˆ");
    
    // åˆ›å»ºMockä¼šè¯
    let session = MockPingoraSession::new()
        .with_auth("test-api-key-12345")
        .with_header("content-type", "application/json")
        .with_header("x-request-id", "test-request-001")
        .with_json_body(&json!({
            "model": "gpt-3.5-turbo",
            "messages": [
                {"role": "user", "content": "Hello, integration test!"}
            ],
            "max_tokens": 100,
            "temperature": 0.7
        }));
    
    // éªŒè¯ä¼šè¯å±æ€§
    assert_eq!(session.get_header("authorization"), Some(&"Bearer test-api-key-12345".to_string()));
    assert_eq!(session.get_header("content-type"), Some(&"application/json".to_string()));
    assert_eq!(session.get_header("x-request-id"), Some(&"test-request-001".to_string()));
    
    // éªŒè¯JSONè¯·æ±‚ä½“
    let parsed_body: serde_json::Value = session.body_as_json()
        .expect("JSONè§£æå¤±è´¥");
    assert_eq!(parsed_body["model"], "gpt-3.5-turbo");
    assert_eq!(parsed_body["messages"][0]["role"], "user");
    assert_eq!(parsed_body["max_tokens"], 100);
    
    println!("   âœ… ä¼šè¯æ¨¡æ‹Ÿå™¨é›†æˆæµ‹è¯•é€šè¿‡");
}

#[tokio::test]
async fn test_environment_helpers_integration() {
    init_test_env();
    
    println!("ğŸŒ æµ‹è¯•ç¯å¢ƒè¾…åŠ©å·¥å…·é›†æˆ");
    
    // æµ‹è¯•ä¸´æ—¶ç¯å¢ƒå˜é‡è®¾ç½®
    let original_value = std::env::var("TEST_INTEGRATION_VAR").ok();
    
    let result = EnvTestHelper::with_env("TEST_INTEGRATION_VAR", "integration_test_value", || {
        std::env::var("TEST_INTEGRATION_VAR").unwrap()
    });
    
    assert_eq!(result, "integration_test_value");
    
    // éªŒè¯ç¯å¢ƒå˜é‡å·²æ¢å¤
    let current_value = std::env::var("TEST_INTEGRATION_VAR").ok();
    assert_eq!(current_value, original_value);
    
    // æµ‹è¯•ä¸´æ—¶ç§»é™¤ç¯å¢ƒå˜é‡
    std::env::set_var("TEMP_TEST_VAR", "temporary");
    
    let result = EnvTestHelper::without_env("TEMP_TEST_VAR", || {
        std::env::var("TEMP_TEST_VAR").is_err()
    });
    
    assert!(result);
    
    // éªŒè¯ç¯å¢ƒå˜é‡å·²æ¢å¤
    assert_eq!(std::env::var("TEMP_TEST_VAR").unwrap(), "temporary");
    std::env::remove_var("TEMP_TEST_VAR");
    
    println!("   âœ… ç¯å¢ƒè¾…åŠ©å·¥å…·é›†æˆæµ‹è¯•é€šè¿‡");
}

#[tokio::test]
async fn test_http_server_mock_integration() {
    init_test_env();
    
    println!("ğŸŒ æµ‹è¯•HTTPæœåŠ¡å™¨Mocké›†æˆ");
    
    // å¯åŠ¨MockæœåŠ¡å™¨
    let server = MockHttpServer::start().await;
    
    // é…ç½®OpenAI Chat Mock
    server.mock_openai_chat("gpt-3.5-turbo", "Hello from integration test!").await;
    
    // é…ç½®é”™è¯¯å“åº”Mock
    server.mock_error("/v1/error", 500, "Internal server error").await;
    
    // éªŒè¯æœåŠ¡å™¨URI
    assert!(!server.uri().is_empty());
    assert!(server.uri().starts_with("http://"));
    
    println!("   âœ… MockæœåŠ¡å™¨å¯åŠ¨æˆåŠŸ: {}", server.uri());
    println!("   âœ… OpenAI Chat Mocké…ç½®æˆåŠŸ");
    println!("   âœ… é”™è¯¯å“åº”Mocké…ç½®æˆåŠŸ");
    
    println!("   âœ… HTTPæœåŠ¡å™¨Mocké›†æˆæµ‹è¯•é€šè¿‡");
}

#[tokio::test]
async fn test_time_mock_integration() {
    init_test_env();
    
    println!("â° æµ‹è¯•æ—¶é—´Mocké›†æˆ");
    
    let base_time = chrono::Utc::now();
    let mock_time = MockTime::new(base_time);
    
    // éªŒè¯åˆå§‹æ—¶é—´
    assert_eq!(mock_time.now(), base_time);
    
    // æµ‹è¯•æ—¶é—´æ¨è¿›
    mock_time.advance(chrono::Duration::minutes(30));
    assert_eq!(mock_time.now(), base_time + chrono::Duration::minutes(30));
    
    // æµ‹è¯•æ—¶é—´è·³è·ƒ
    let future_time = base_time + chrono::Duration::days(1);
    mock_time.set(future_time);
    assert_eq!(mock_time.now(), future_time);
    
    // æµ‹è¯•æ—¶é—´å›é€€
    let past_time = base_time - chrono::Duration::hours(2);
    mock_time.set(past_time);
    assert_eq!(mock_time.now(), past_time);
    
    println!("   âœ… æ—¶é—´æ¨è¿›æµ‹è¯•é€šè¿‡");
    println!("   âœ… æ—¶é—´è·³è·ƒæµ‹è¯•é€šè¿‡");
    println!("   âœ… æ—¶é—´å›é€€æµ‹è¯•é€šè¿‡");
    
    println!("   âœ… æ—¶é—´Mocké›†æˆæµ‹è¯•é€šè¿‡");
}

#[tokio::test]
async fn test_comprehensive_integration_scenario() {
    init_test_env();
    
    println!("ğŸš€ ç»¼åˆé›†æˆæµ‹è¯•åœºæ™¯");
    
    // 1. æ•°æ®åº“å’Œäº‹åŠ¡è®¾ç½®
    let tx = TestTransaction::new().await
        .expect("åˆ›å»ºæµ‹è¯•äº‹åŠ¡å¤±è´¥");
    
    // 2. åˆ›å»ºæµ‹è¯•ç”¨æˆ·
    let user_fixture = UserFixture::new()
        .username("comprehensive_user")
        .email("comprehensive@test.com")
        .admin();
    
    let user_id = tx.insert_test_user(user_fixture).await
        .expect("æ’å…¥æµ‹è¯•ç”¨æˆ·å¤±è´¥");
    
    // 3. åˆ›å»ºæä¾›å•†
    let mut provider_fixture = ProviderTypeFixture::openai();
    provider_fixture.name = sea_orm::Set("comprehensive_openai".to_string());
    let provider_id = tx.insert_provider_type(provider_fixture).await
        .expect("æ’å…¥æä¾›å•†å¤±è´¥");
    
    // 4. ä½¿ç”¨æ—¶é—´Mockæ§åˆ¶æµ‹è¯•æ—¶é—´
    let test_time = chrono::Utc::now();
    let mock_time = MockTime::new(test_time);
    
    // 5. å¯åŠ¨Mock HTTPæœåŠ¡å™¨
    let server = MockHttpServer::start().await;
    server.mock_openai_chat("gpt-3.5-turbo", "Comprehensive test response!").await;
    
    // 6. åˆ›å»ºMock Pingoraä¼šè¯
    let session = MockPingoraSession::new()
        .with_auth("comprehensive-test-key")
        .with_header("x-test-scenario", "comprehensive")
        .with_json_body(&json!({
            "model": "gpt-3.5-turbo",
            "messages": [
                {"role": "system", "content": "You are a helpful assistant."},
                {"role": "user", "content": "Run comprehensive integration test"}
            ],
            "max_tokens": 200,
            "temperature": 0.8,
            "stream": false
        }));
    
    // 7. æµ‹é‡æ•´ä¸ªåœºæ™¯çš„æ€§èƒ½
    let (scenario_result, total_duration) = PerformanceTest::measure_async(|| async {
        // æ¨¡æ‹Ÿå®Œæ•´çš„è¯·æ±‚å¤„ç†æµç¨‹
        
        // 7.1. éªŒè¯ä¼šè¯æ•°æ®
        let auth_header = session.get_header("authorization").unwrap();
        assert!(auth_header.starts_with("Bearer "));
        
        let body: serde_json::Value = session.body_as_json().unwrap();
        assert_eq!(body["model"], "gpt-3.5-turbo");
        assert_eq!(body["messages"].as_array().unwrap().len(), 2);
        
        // 7.2. æ¨¡æ‹Ÿæ—¶é—´æ¨è¿›
        mock_time.advance(chrono::Duration::milliseconds(150));
        
        // 7.3. åˆ›å»ºMock AIå“åº”
        let mock_provider = MockOpenAiProvider::new();
        let ai_request = api_proxy::testing::mocks::ChatCompletionRequest {
            model: body["model"].as_str().unwrap().to_string(),
            messages: vec![
                api_proxy::testing::mocks::ChatMessage {
                    role: "user".to_string(),
                    content: "Comprehensive test".to_string(),
                }
            ],
            temperature: Some(0.8),
            max_tokens: Some(200),
        };
        
        let ai_response = mock_provider.chat_completion(ai_request).await
            .expect("AIå“åº”ç”Ÿæˆå¤±è´¥");
        
        // 7.4. éªŒè¯å“åº”
        assert_eq!(ai_response.model, "gpt-3.5-turbo");
        assert!(!ai_response.choices.is_empty());
        assert!(ai_response.usage.is_some());
        
        // 7.5. å¥åº·æ£€æŸ¥
        let health = mock_provider.health_check().await
            .expect("å¥åº·æ£€æŸ¥å¤±è´¥");
        assert_eq!(health.status, "healthy");
        
        "comprehensive_scenario_success"
    }).await;
    
    // 8. éªŒè¯ç»¼åˆæµ‹è¯•ç»“æœ
    assert_eq!(scenario_result, "comprehensive_scenario_success");
    assert!(total_duration < std::time::Duration::from_secs(5)); // åº”è¯¥åœ¨5ç§’å†…å®Œæˆ
    
    println!("   âœ… æ•°æ®åº“æ“ä½œ: ç”¨æˆ·ID {}, æä¾›å•†ID {}", user_id, provider_id);
    println!("   âœ… MockæœåŠ¡: HTTPæœåŠ¡å™¨ {}", server.uri());
    println!("   âœ… ä¼šè¯æ¨¡æ‹Ÿ: åŒ…å«è®¤è¯å’ŒJSONæ•°æ®");
    println!("   âœ… æ—¶é—´æ§åˆ¶: æ¨è¿›150ms");
    println!("   âœ… AIæ¨¡æ‹Ÿ: OpenAIèŠå¤©å®Œæˆ");
    println!("   âœ… æ€§èƒ½æµ‹é‡: æ€»è€—æ—¶ {:?}", total_duration);
    
    println!("ğŸ‰ ç»¼åˆé›†æˆæµ‹è¯•åœºæ™¯é€šè¿‡ï¼");
}

#[tokio::test]
async fn test_error_handling_integration() {
    init_test_env();
    
    println!("âŒ æµ‹è¯•é”™è¯¯å¤„ç†é›†æˆ");
    
    // 1. æµ‹è¯•Mock AIæä¾›å•†é”™è¯¯
    let failing_provider = MockOpenAiProvider::new().with_failure();
    
    let request = api_proxy::testing::mocks::ChatCompletionRequest {
        model: "gpt-3.5-turbo".to_string(),
        messages: vec![],
        temperature: Some(0.7),
        max_tokens: Some(100),
    };
    
    let ai_result = failing_provider.chat_completion(request).await;
    assert!(ai_result.is_err());
    println!("   âœ… AIæä¾›å•†é”™è¯¯æ¨¡æ‹ŸæˆåŠŸ");
    
    let health_result = failing_provider.health_check().await;
    assert!(health_result.is_err());
    println!("   âœ… å¥åº·æ£€æŸ¥é”™è¯¯æ¨¡æ‹ŸæˆåŠŸ");
    
    // 2. æµ‹è¯•ä¸å¥åº·çš„Mockæä¾›å•†
    let unhealthy_provider = MockOpenAiProvider::new().unhealthy();
    
    let health_status = unhealthy_provider.health_check().await
        .expect("ä¸å¥åº·çŠ¶æ€æ£€æŸ¥å¤±è´¥");
    assert_eq!(health_status.status, "unhealthy");
    assert!(health_status.response_time_ms > 1000); // æ¨¡æ‹Ÿé«˜å»¶è¿Ÿ
    println!("   âœ… ä¸å¥åº·çŠ¶æ€æ¨¡æ‹ŸæˆåŠŸ");
    
    // 3. æµ‹è¯•æ— æ•ˆä¼šè¯æ•°æ®
    let invalid_session = MockPingoraSession::new()
        .with_auth("invalid-token")
        .with_body(b"invalid json {");
    
    let json_result: Result<serde_json::Value, _> = invalid_session.body_as_json();
    assert!(json_result.is_err());
    println!("   âœ… æ— æ•ˆJSONé”™è¯¯å¤„ç†æˆåŠŸ");
    
    // 4. æµ‹è¯•ç¯å¢ƒå˜é‡é”™è¯¯å¤„ç†
    let env_result = EnvTestHelper::with_env("", "value", || {
        std::env::var("NONEXISTENT_VAR").is_err()
    });
    assert!(env_result);
    println!("   âœ… ç¯å¢ƒå˜é‡é”™è¯¯å¤„ç†æˆåŠŸ");
    
    println!("âŒ é”™è¯¯å¤„ç†é›†æˆæµ‹è¯•é€šè¿‡ï¼");
}

#[tokio::test]
async fn test_complete_system_integration() {
    init_test_env();
    
    println!("ğŸŒŸ å®Œæ•´ç³»ç»Ÿé›†æˆæµ‹è¯•");
    
    // æµ‹è¯•æ‰€æœ‰ç»„ä»¶çš„ååŒå·¥ä½œ
    println!("   ğŸ”§ è®¾ç½®æµ‹è¯•ç¯å¢ƒ...");
    
    // 1. æ•°æ®åº“å±‚
    let tx = TestTransaction::new().await
        .expect("æ•°æ®åº“è®¾ç½®å¤±è´¥");
    
    // 2. é…ç½®å±‚
    let config = TestConfig::app_config();
    assert_eq!(config.server.as_ref().unwrap().host, "127.0.0.1");
    
    // 3. ç”¨æˆ·æ•°æ®å±‚
    let user_fixture = UserFixture::new()
        .username("system_test_user")
        .email("system@test.com");
    let user_id = tx.insert_test_user(user_fixture).await
        .expect("ç”¨æˆ·åˆ›å»ºå¤±è´¥");
    
    // 4. æä¾›å•†æ•°æ®å±‚
    let mut provider_fixture = ProviderTypeFixture::openai();
    provider_fixture.name = sea_orm::Set("system_test_openai".to_string());
    let provider_id = tx.insert_provider_type(provider_fixture).await
        .expect("æä¾›å•†åˆ›å»ºå¤±è´¥");
    
    // 5. MockæœåŠ¡å±‚
    let server = MockHttpServer::start().await;
    server.mock_openai_chat("gpt-3.5-turbo", "System integration response").await;
    
    let mock_provider = MockOpenAiProvider::new();
    
    // 6. ä¼šè¯å±‚
    let session = MockPingoraSession::new()
        .with_auth("system-integration-key")
        .with_header("x-integration-test", "system")
        .with_json_body(&json!({
            "model": "gpt-3.5-turbo",
            "messages": [{"role": "user", "content": "System integration test"}],
            "max_tokens": 150
        }));
    
    // 7. æ—¶é—´æ§åˆ¶å±‚
    let mock_time = MockTime::new(chrono::Utc::now());
    
    println!("   ğŸš€ æ‰§è¡Œç³»ç»Ÿé›†æˆæµç¨‹...");
    
    // æ‰§è¡Œå®Œæ•´çš„é›†æˆæµ‹è¯•æµç¨‹
    let integration_result = async {
        // æ­¥éª¤1: éªŒè¯æ•°æ®å±‚
        assert!(user_id > 0);
        assert!(provider_id > 0);
        
        // æ­¥éª¤2: éªŒè¯ä¼šè¯å±‚
        assert_eq!(session.get_header("authorization"), Some(&"Bearer system-integration-key".to_string()));
        let body: serde_json::Value = session.body_as_json()?;
        assert_eq!(body["model"], "gpt-3.5-turbo");
        
        // æ­¥éª¤3: éªŒè¯MockæœåŠ¡å±‚
        let health = mock_provider.health_check().await?;
        assert_eq!(health.status, "healthy");
        
        let ai_request = api_proxy::testing::mocks::ChatCompletionRequest {
            model: "gpt-3.5-turbo".to_string(),
            messages: vec![
                api_proxy::testing::mocks::ChatMessage {
                    role: "user".to_string(),
                    content: "System test".to_string(),
                }
            ],
            temperature: Some(0.7),
            max_tokens: Some(150),
        };
        
        let ai_response = mock_provider.chat_completion(ai_request).await?;
        assert_eq!(ai_response.model, "gpt-3.5-turbo");
        
        // æ­¥éª¤4: éªŒè¯æ—¶é—´æ§åˆ¶å±‚
        let start_time = mock_time.now();
        mock_time.advance(chrono::Duration::seconds(1));
        let end_time = mock_time.now();
        assert_eq!(end_time - start_time, chrono::Duration::seconds(1));
        
        // æ­¥éª¤5: éªŒè¯é…ç½®å±‚
        assert_eq!(config.database.url, ":memory:");
        assert_eq!(config.redis.database, 15);
        
        Ok::<_, Box<dyn std::error::Error>>("system_integration_success")
    }.await;
    
    match integration_result {
        Ok(result) => {
            assert_eq!(result, "system_integration_success");
            println!("   âœ… ç³»ç»Ÿé›†æˆæµç¨‹æ‰§è¡ŒæˆåŠŸ");
        }
        Err(e) => {
            panic!("ç³»ç»Ÿé›†æˆæµç¨‹å¤±è´¥: {}", e);
        }
    }
    
    println!("ğŸ‰ å®Œæ•´ç³»ç»Ÿé›†æˆæµ‹è¯•é€šè¿‡ï¼");
    println!("âœ¨ éªŒè¯å®Œæˆçš„ç³»ç»Ÿå±‚æ¬¡ï¼š");
    println!("   - âœ… æ•°æ®åº“å±‚: ç”¨æˆ·å’Œæä¾›å•†ç®¡ç†");
    println!("   - âœ… é…ç½®å±‚: åº”ç”¨é…ç½®ç®¡ç†");
    println!("   - âœ… MockæœåŠ¡å±‚: å¤–éƒ¨æœåŠ¡æ¨¡æ‹Ÿ");
    println!("   - âœ… ä¼šè¯å±‚: è¯·æ±‚ä¼šè¯æ¨¡æ‹Ÿ");
    println!("   - âœ… æ—¶é—´æ§åˆ¶å±‚: æ—¶é—´ç®¡ç†æ¨¡æ‹Ÿ");
    println!("   - âœ… é”™è¯¯å¤„ç†å±‚: å¼‚å¸¸æƒ…å†µå¤„ç†");
    println!("   - âœ… æ€§èƒ½æµ‹é‡å±‚: æ€§èƒ½ç›‘æ§");
    println!("   - âœ… ç»„ä»¶åä½œ: è·¨å±‚æ¬¡é›†æˆ");
}